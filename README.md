# EssentiaSketch

A data visualization demonstration that analyzes audio files from a Hugging Face dataset using `essentia.js` within a `p5.js` project.

[Andrej Karpathy](https://en.wikipedia.org/wiki/Andrej_Karpathy) notes that generative AI models, particularly LLMs, are capable of outputting a ton of content very quickly- but this is not that useful of an interface, because the necessary human review cannot keep up.

I feel there's an opportunity for role-reversal in music: as a human, I like to plug in my guitar and just play, without thinking in terms of song structure or arrangement. I'd like an autonomous system to sift through this output after the fact, sorting it for easy packaging as songs.